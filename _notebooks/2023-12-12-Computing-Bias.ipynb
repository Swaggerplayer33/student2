{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "toc: true\n",
    "comments: true\n",
    "layout: post\n",
    "title: Computing Bias\n",
    "description: College Board Big Idea 5.3 Computing Bias Student Lesson\n",
    "type: hacks\n",
    "courses: { compsci: {week: 15} }\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Biases Reflected As Computer Biases\n",
    "\n",
    "**Bias**: prejudice in favor of or against a thing, person, or group\n",
    "\n",
    "## What is \"computer bias\"?\n",
    "The existence of prejudiced outcomes in the decisions or predictions made by computer systems/algorithms. Bias can be implemented into algorithms because of human biases being intentionally inserted or because of the data utilized being biased.\n",
    "\n",
    "**Explicit Data:**\n",
    "Information directly provided by user.\n",
    "\n",
    "**Implicit Data:**\n",
    "Infomration that can inferred from explicit data. \n",
    "\n",
    "Based on either explicit/implicit data that has been used to train an algorithm, whether intentionally introduced or during the process of training data generation, bias can be created.\n",
    "\n",
    "<img src=\"https://static01.nyt.com/images/2020/03/10/multimedia/ihw-nudgebias/ihw-nudgebias-mediumSquareAt3X.jpg\" width=\"450\" length=\"450\">\n",
    "\n",
    "A notable example of this is seen in Netflix, where there are is a human factor that drives bias: Netflix exclusives are placed ahead (a show that is a Netflix exclusive means that users will be more likely to stay with Netflix). The bias in this case is Netflix's prioritzation towards Netflix-produced shows.\n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*8BtlgpxyjOPaLZXO6pVD0Q.jpeg\" width=\"700\" length=\"394\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hack 1: \n",
    "What is another example of a human bias being implemented into an algorithm? \n",
    "> Answer: Instagram is meant for youth\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing Bias\n",
    "Programmers should take action to reduce bias in algorithms used for computing innovations as a way of combating existing human biases. Softwares need to be unbiased, consider all everything, and reject human bias.\n",
    "\n",
    "Things to consider when developing programs:\n",
    "- What are potential sources of bias?\n",
    "- Is your program enhancing or intentionally excluding?\n",
    "- Are you receiving feedback from a widespread group of people?\n",
    "- How could people who differ from you use your developments?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hack 2: \n",
    "What is another way a programmer can reduce bias in their softwares?\n",
    "> Answer:Another way programmers can reduce bias in their software is by implementing fairness-aware algorithms and models. Fairness-aware techniques aim to mitigate biases in the outcomes of algorithms by considering and addressing potential disparities among different groups. This involves designing algorithms that not only optimize for accuracy but also take into account fairness metrics, ensuring equitable results across various demographic or user segments.\n",
    "\n",
    "For example, in a hiring algorithm, a fairness-aware approach would involve assessing the impact of the algorithm on different groups (based on gender, ethnicity, etc.) and adjusting the model to minimize any disparate impact. This might include re-weighting the training data, adjusting decision thresholds, or incorporating specific fairness constraints during the model optimization process.\n",
    "\n",
    "By actively incorporating fairness considerations into the algorithmic design and development process, programmers can contribute to the creation of more equitable and unbiased software systems. Regular testing and validation against fairness metrics can help identify and rectify potential biases, fostering a commitment to ethical and inclusive software development practices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of Bias in Software Development\n",
    "Biases can be embedded at all levels of software development.\n",
    "\n",
    "It can be intentional or unintentional. Some software development are made for a certain market and ensure that people of certain places or demographics can use them easily. However, this doesn't mean that they are trying to exclude.  \n",
    "\n",
    "Examples: \n",
    "\n",
    "**Intentional**: \n",
    "- Games could be geared towards a certain age range (Talking Tom vs Valorant)\n",
    "    - Game concepts\n",
    "    - Music\n",
    "    - Visuals\n",
    "\n",
    "<img src=\"https://is1-ssl.mzstatic.com/image/thumb/PurpleSource126/v4/fb/63/3e/fb633e5e-920b-aab4-3b5e-770edca48ca8/011eb6d7-683f-4586-8794-fa67e2dfc403_screenshot_ipad_en-US_6577036012549030604.jpg/643x0w.jpg\" width=\"429\" length=\"572\">\n",
    "<img src=\"https://www.pcgameshardware.de/screenshots/1280x/2020/03/Reveal_Window_VALORANT-pcgh.jpg\" width=\"640\" length=\"360\">\n",
    "\n",
    "- WeChat and KakaoTalk\n",
    "    - Almost everyone in China uses WeChat\n",
    "    - KakaoTalk is the Korean version\n",
    "\n",
    "**Unintentional**: \n",
    "- Social media, Facebook vs. instagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hack 3:\n",
    "What are some other examples of intentional and/or unintentional bias in innovations (games, social media, technology, etc.)?\n",
    "> Answer: \n",
    "Bias in innovations is pervasive and can occur intentionally or unintentionally across various domains. In facial recognition technology, intentional bias arises when datasets lack diversity, favoring certain ethnic groups. Algorithms used in hiring processes may perpetuate discrimination if trained on biased historical data, while social media algorithms intentionally optimize for engagement, potentially reinforcing filter bubbles. Video games can exhibit intentional biases in character portrayals based on cultural or gender norms. In healthcare, intentional biases may emerge if algorithms are trained on data reflecting existing disparities. Language translation services can unintentionally reinforce stereotypes due to cultural biases in language. Recognizing and addressing these biases is crucial to ensuring that innovations are fair, inclusive, and equitable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "### Question 1: \n",
    "Define \"computer bias\" in your own words and explain how it can result from intentional or unintentional factors in software development. Give a brief example of this. Explain how programmers can actively work to reduce bias in their algorithms?\n",
    "\n",
    "> Answer: \"Computer bias\" refers to the presence of unfair or discriminatory outcomes in computational processes, often stemming from skewed data, flawed algorithms, or preconceived notions encoded into software. This bias can result from intentional actions, such as the explicit inclusion of prejudiced criteria in algorithm design, or unintentional factors, like biased training data influencing machine learning models. For instance, if a facial recognition system is trained predominantly on images of individuals from a specific demographic, it may struggle to accurately recognize faces from underrepresented groups. Programmers can actively work to reduce bias by employing diverse and representative datasets during training, regularly auditing algorithms for discriminatory patterns, and fostering inclusivity within development teams to consider a broader range of perspectives. Additionally, implementing transparency and accountability mechanisms in algorithmic decision-making processes can help mitigate unintended biases.\n",
    "\n",
    "\n",
    "### Question 2:\n",
    "Briefly describe the two types of bias in software development and provide examples from the gaming industry and social media platforms. How might biases in software design affect user engagement and experiences?\n",
    "\n",
    "> Answer: \n",
    "In software development, biases can manifest as intentional or unintentional, influencing user experiences. Intentional bias involves purposeful inclusion of prejudiced elements, while unintentional bias arises inadvertently, often from biased data or flawed algorithms.\n",
    "\n",
    "1. Intentional Bias:\n",
    "\n",
    "Gaming Industry Example: Game developers may intentionally depict characters or scenarios reinforcing stereotypes or biased cultural norms to appeal to specific target audiences.\n",
    "Social Media Example: Platforms might deliberately prioritize or suppress content based on political, social, or commercial motives, shaping users' perspectives and interactions.\n",
    "2. Unintentional Bias:\n",
    "\n",
    "Gaming Industry Example: If game developers use biased datasets for character design or story development, unintentional biases may emerge, impacting how certain groups are represented in games.\n",
    "Social Media Example: Algorithms on social media platforms may unintentionally favor certain content, perpetuating filter bubbles and limiting the diversity of information users are exposed to.\n",
    "Biases in software design can significantly affect user engagement and experiences. Users may encounter content, recommendations, or interactions that align with existing biases, reinforcing their preconceptions and limiting exposure to diverse perspectives. This can contribute to echo chambers, polarization, and inequitable experiences for different user groups. Addressing these biases is crucial for creating inclusive, fair, and engaging digital environments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
